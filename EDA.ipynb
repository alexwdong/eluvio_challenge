{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "religious-signature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cordless-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import bernoulli\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils import make_all_dot_product_features_df,make_dot_product_features, make_all_embedding_difference_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-decision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "preliminary-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/jolteon/eluvio_challenge/data/train/tt0052357.pkl'\n",
    "\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "economic-presence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['place', 'cast', 'action', 'audio', 'scene_transition_boundary_ground_truth', 'shot_end_frame', 'scene_transition_boundary_prediction', 'imdb_id'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-translation",
   "metadata": {},
   "source": [
    "Shot-level: four features, preprocessed and encoded as 2D tensors\n",
    "\n",
    "    place: num x 2048\n",
    "    cast: num x 512,\n",
    "    action: num x 512\n",
    "    audio: num x 512\n",
    "\n",
    "\n",
    "Scene-level:\n",
    " Ground truth (‘scene_transition_boundary_ground_truth’) is a boolean vector\n",
    "labeling scene transition boundaries.\n",
    "b. Preliminary scene transition prediction (‘scene_transition_boundary_prediction’)\n",
    "is a prediction template, meaning your final output should resemble the format\n",
    "and calculate the probability of a shot boundary being a scene boundary, i.e.\n",
    "- 1 -\n",
    "contain one score (between 0 and 1) for each shot transition. You’re also\n",
    "welcome to utilize the preliminary results for your predictions.\n",
    "c. The 'shot_end_frame' is the end frame index for each shot, which is provided for\n",
    "evaluation only.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "increasing-psychology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['scene_transition_boundary_ground_truth'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "comparable-marsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['scene_transition_boundary_prediction'].numpy(),bins=[0,0.01,0.05,0.1,.2,.3,.4,.5,.6,.7,.8,.9,.95,.99,1.01])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "seeing-option",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 1.01]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,0.01,0.05,0.1,.2,.3,.4,.5,.6,.7,.8,.9,.95,.99,1.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "original-crowd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1101])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['shot_end_frame'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dynamic-carry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1101, 2048])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['place'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interim-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['scene_transition_boundary_ground_truth'].numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "spiritual-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_boundary_truth = data['scene_transition_boundary_ground_truth'].numpy().astype(int)\n",
    "place_embedding = data['place'].numpy()\n",
    "cast_embedding = data['cast'].numpy()\n",
    "action_embedding = data['action'].numpy()\n",
    "audio_embedding = data['audio'].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "renewable-worse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_boundary_truth.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-horse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "split-promotion",
   "metadata": {},
   "source": [
    "# Random Forest Boundary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "respective-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/jolteon/eluvio_challenge/data/train/'\n",
    "val_dir = '/home/jolteon/eluvio_challenge/data/val/'\n",
    "test_dir = '/home/jolteon/eluvio_challenge/data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "vertical-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "data_train = make_all_dot_product_features_df(train_dir)\n",
    "data_val =  make_all_dot_product_features_df(test_dir)\n",
    "#Combine, since we are going to do crossval\n",
    "data_train = pd.concat([data_train,data_val])\n",
    "#seperate X,y\n",
    "X_train = data_train[['place_dp','cast_dp','action_dp','audio_dp']]\n",
    "y_train = data_train['boundary_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "pressed-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_dp</th>\n",
       "      <th>cast_dp</th>\n",
       "      <th>action_dp</th>\n",
       "      <th>audio_dp</th>\n",
       "      <th>boundary_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.192154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489.716553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>445.407837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292.007690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350.747498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>465.193115</td>\n",
       "      <td>1.518258</td>\n",
       "      <td>4138.864258</td>\n",
       "      <td>0.256540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>346.203339</td>\n",
       "      <td>0.560668</td>\n",
       "      <td>2765.230713</td>\n",
       "      <td>0.594189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>265.108948</td>\n",
       "      <td>0.575942</td>\n",
       "      <td>2732.739258</td>\n",
       "      <td>0.731078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>286.565979</td>\n",
       "      <td>0.641870</td>\n",
       "      <td>3133.891602</td>\n",
       "      <td>0.502469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>162.490417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93539 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        place_dp   cast_dp    action_dp  audio_dp  boundary_truth\n",
       "0      91.192154  0.000000     0.000000  0.584730               0\n",
       "1     489.716553  0.000000     0.000000  0.231411               0\n",
       "2     445.407837  0.000000     0.000000  0.364196               0\n",
       "3     292.007690  0.000000     0.000000  0.850917               0\n",
       "4     350.747498  0.000000     0.000000  0.737919               0\n",
       "...          ...       ...          ...       ...             ...\n",
       "1868  465.193115  1.518258  4138.864258  0.256540               1\n",
       "1869  346.203339  0.560668  2765.230713  0.594189               1\n",
       "1870  265.108948  0.575942  2732.739258  0.731078               1\n",
       "1871  286.565979  0.641870  3133.891602  0.502469               0\n",
       "1872  162.490417  0.000000     0.000000  0.483134               1\n",
       "\n",
       "[93539 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-ethernet",
   "metadata": {},
   "source": [
    "### Random forest/Logisitc Grid on dot product features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "checked-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 251 ms, total: 1min 3s\n",
      "Wall time: 21min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [10, 15, 20, 25, 30],\n",
       "                         'min_samples_leaf': [100, 50, 10],\n",
       "                         'n_estimators': [500]},\n",
       "             scoring='average_precision')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "#param_grid = {'n_estimators': [500],\n",
    "#              'min_samples_leaf': [100,50,10],\n",
    "#              'max_depth': [10,15,20,25,30],\n",
    "#             }\n",
    "#clf = GridSearchCV(\n",
    "#        RandomForestClassifier(),param_grid,scoring='average_precision',n_jobs=4)\n",
    "#clf.fit(X_train, y_train)                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-renewal",
   "metadata": {},
   "source": [
    "Fitting an RF model takes approximately 1 minute per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "apparent-ground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 379 ms, sys: 141 ms, total: 520 ms\n",
      "Wall time: 3.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=4,\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 0.1, 10, 100]},\n",
       "             scoring='average_precision')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'C' : [.0001,.001,.01,.1,.1,10,100]\n",
    "             }\n",
    "clf = GridSearchCV(\n",
    "        LogisticRegression(),param_grid,scoring='average_precision',n_jobs=4)\n",
    "clf.fit(X_train, y_train)                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-aaron",
   "metadata": {},
   "source": [
    "Fitting an Logistic model is extremely fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "parliamentary-burke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.21675997, 0.19524693, 0.19588537, 0.21763601, 0.21203732,\n",
       "        0.1893826 , 0.18527846]),\n",
       " 'std_fit_time': array([0.03485587, 0.04589468, 0.0646747 , 0.06798589, 0.04875244,\n",
       "        0.03981532, 0.04223883]),\n",
       " 'mean_score_time': array([0.00563293, 0.00579257, 0.00636811, 0.00599527, 0.00565615,\n",
       "        0.00563054, 0.00535917]),\n",
       " 'std_score_time': array([0.00033247, 0.00067348, 0.00072163, 0.00090026, 0.00021436,\n",
       "        0.000182  , 0.0002019 ]),\n",
       " 'param_C': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 0.1, 10, 100],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.0001},\n",
       "  {'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.1},\n",
       "  {'C': 0.1},\n",
       "  {'C': 10},\n",
       "  {'C': 100}],\n",
       " 'split0_test_score': array([0.13326722, 0.13751316, 0.14066426, 0.14109236, 0.14109236,\n",
       "        0.14113692, 0.1411376 ]),\n",
       " 'split1_test_score': array([0.13501104, 0.14443349, 0.14654727, 0.14638424, 0.14638424,\n",
       "        0.14641699, 0.1464117 ]),\n",
       " 'split2_test_score': array([0.13069344, 0.13689901, 0.13928734, 0.13898861, 0.13898861,\n",
       "        0.13902363, 0.13902452]),\n",
       " 'split3_test_score': array([0.13680376, 0.14491128, 0.1463286 , 0.14626913, 0.14626913,\n",
       "        0.14624219, 0.14623942]),\n",
       " 'split4_test_score': array([0.13983134, 0.14375223, 0.14321453, 0.14374871, 0.14374871,\n",
       "        0.1437145 , 0.14371334]),\n",
       " 'mean_test_score': array([0.13512136, 0.14150183, 0.1432084 , 0.14329661, 0.14329661,\n",
       "        0.14330685, 0.14330532]),\n",
       " 'std_test_score': array([0.00310067, 0.0035321 , 0.00292339, 0.00289798, 0.00289798,\n",
       "        0.00288132, 0.00287921]),\n",
       " 'rank_test_score': array([7, 6, 5, 3, 3, 1, 2], dtype=int32)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "blessed-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "therapeutic-hello",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=100, n_estimators=500)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-amount",
   "metadata": {},
   "source": [
    "# Random Forest / Logistic Regression on difference of embeddings features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "quantitative-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/jolteon/eluvio_challenge/data/train/'\n",
    "val_dir = '/home/jolteon/eluvio_challenge/data/val/'\n",
    "test_dir = '/home/jolteon/eluvio_challenge/data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "attractive-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train= make_all_embedding_difference_features_df(train_dir)\n",
    "X_val,y_val =  make_all_embedding_difference_features_df(test_dir)\n",
    "#Combine, since we are going to do crossval\n",
    "#data_train = pd.concat([data_train,data_val])\n",
    "#seperate X,y\n",
    "X = np.vstack([X_train,X_val])\n",
    "y = np.concatenate([y_train,y_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "correct-veteran",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93539, 3584)\n",
      "(93539,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "annual-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolteon/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jolteon/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jolteon/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jolteon/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jolteon/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 5.82 s, total: 2min 21s\n",
      "Wall time: 2min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolteon/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), param_grid={'C': [1]},\n",
       "             scoring='average_precision')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#param_grid = {'C' : [.0001,.001,.01,.1,.1,10,100]\n",
    "#             }\n",
    "param_grid = {'C' : [1]\n",
    "             }\n",
    "clf = GridSearchCV(\n",
    "        LogisticRegression(),param_grid,scoring='average_precision')\n",
    "clf.fit(X, y)                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "painted-treasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([22.97734632]),\n",
       " 'std_fit_time': array([1.3481681]),\n",
       " 'mean_score_time': array([0.24742317]),\n",
       " 'std_score_time': array([0.03400968]),\n",
       " 'param_C': masked_array(data=[1],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1}],\n",
       " 'split0_test_score': array([0.11180202]),\n",
       " 'split1_test_score': array([0.10383492]),\n",
       " 'split2_test_score': array([0.10508855]),\n",
       " 'split3_test_score': array([0.10298367]),\n",
       " 'split4_test_score': array([0.10233287]),\n",
       " 'mean_test_score': array([0.1052084]),\n",
       " 'std_test_score': array([0.00342329]),\n",
       " 'rank_test_score': array([1], dtype=int32)}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-syndicate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "verbal-short",
   "metadata": {},
   "source": [
    "# Prediction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "annual-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_to_save = '/home/jolteon/eluvio_challenge/baseline_dot_product'\n",
    "#best_model\n",
    "for file in os.listdir(test_dir):\n",
    "    if file.endswith('.pkl'):\n",
    "        with open(test_dir+file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = make_dot_product_features(data)\n",
    "        X = df['place_dp','cast_dp','action_dp','audio_dp']\n",
    "        predictions = best_model.predict_proba(X)[:,1]\n",
    "        data_to_pkl={}\n",
    "        data_to_pkl['scene_transition_boundary_ground_truth'] = \\\n",
    "            data['scene_transition_boundary_ground_truth'].numpy().astype(float)\n",
    "        data_to_pkl['scene_transition_boundary_prediction'] = \\\n",
    "            predictions\n",
    "        data_to_pkl['shot_end_frame'] = data['shot_end_frame']\n",
    "        data_to_pkl['imdb_id'] = file[:-4]\n",
    "\n",
    "        with open(dir_to_save+file, 'wb') as f:\n",
    "            pickle.dump(data_to_pkl,f)\n",
    "                \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "incorporated-generation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1981855 , 0.18860701, 0.08471412, ..., 0.02488697, 0.04490552,\n",
       "       0.15358644])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba(df[['place_dp','cast_dp','action_dp','audio_dp']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "blond-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = best_model.predict_proba(df[['place_dp','cast_dp','action_dp','audio_dp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "raised-forward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['boundary_truth'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "saved-concern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188.5682480466207"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prediction'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "otherwise-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.805527\n",
       "1       0.811739\n",
       "2       0.917920\n",
       "3       0.926434\n",
       "4       0.914055\n",
       "          ...   \n",
       "2390    0.941737\n",
       "2391    0.967304\n",
       "2392    0.973902\n",
       "2393    0.950620\n",
       "2394    0.851580\n",
       "Name: prediction, Length: 2395, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "documented-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80552714, 0.19447286],\n",
       "       [0.81173921, 0.18826079],\n",
       "       [0.91792041, 0.08207959],\n",
       "       ...,\n",
       "       [0.97390155, 0.02609845],\n",
       "       [0.95062027, 0.04937973],\n",
       "       [0.85158004, 0.14841996]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba(df[['place_dp','cast_dp','action_dp','audio_dp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "intellectual-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_dp</th>\n",
       "      <th>cast_dp</th>\n",
       "      <th>action_dp</th>\n",
       "      <th>audio_dp</th>\n",
       "      <th>boundary_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.424072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157.870056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.724617</td>\n",
       "      <td>0.778729</td>\n",
       "      <td>3500.740723</td>\n",
       "      <td>0.336267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165.181152</td>\n",
       "      <td>0.835795</td>\n",
       "      <td>3623.486328</td>\n",
       "      <td>0.344319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.931419</td>\n",
       "      <td>0.733072</td>\n",
       "      <td>3769.134033</td>\n",
       "      <td>0.181464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>405.716431</td>\n",
       "      <td>0.726916</td>\n",
       "      <td>3841.790283</td>\n",
       "      <td>0.540637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>515.628113</td>\n",
       "      <td>0.770968</td>\n",
       "      <td>3770.466309</td>\n",
       "      <td>0.875773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>458.387207</td>\n",
       "      <td>0.739174</td>\n",
       "      <td>4242.908203</td>\n",
       "      <td>0.892689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>369.912415</td>\n",
       "      <td>0.596361</td>\n",
       "      <td>5012.264160</td>\n",
       "      <td>0.356102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>186.266525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2395 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        place_dp   cast_dp    action_dp  audio_dp  boundary_truth\n",
       "0     118.424072  0.000000     0.000000  0.434202               0\n",
       "1     157.870056  0.000000     0.000000  0.111475               0\n",
       "2     127.724617  0.778729  3500.740723  0.336267               0\n",
       "3     165.181152  0.835795  3623.486328  0.344319               0\n",
       "4     106.931419  0.733072  3769.134033  0.181464               0\n",
       "...          ...       ...          ...       ...             ...\n",
       "2390  405.716431  0.726916  3841.790283  0.540637               0\n",
       "2391  515.628113  0.770968  3770.466309  0.875773               0\n",
       "2392  458.387207  0.739174  4242.908203  0.892689               0\n",
       "2393  369.912415  0.596361  5012.264160  0.356102               0\n",
       "2394  186.266525  0.000000     0.000000  0.877146               0\n",
       "\n",
       "[2395 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-bacteria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prostate-practice",
   "metadata": {},
   "source": [
    "# Scratchwork Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "engaged-guess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of IMDB IDs: 64\n",
      "Scores: {\n",
      "    \"AP\": 0.0767715899777535,\n",
      "    \"mAP\": 0.08082663001958115,\n",
      "    \"Miou\": 0.2977235355218801,\n",
      "    \"Precision\": 0.08384742911615159,\n",
      "    \"Recall\": 0.0835096507178984,\n",
      "    \"F1\": 0.08012348697903306\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate_sceneseg.py baseline_random/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "automotive-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of IMDB IDs: 8\n",
      "Scores: {\n",
      "    \"AP\": 0.4799354967433886,\n",
      "    \"mAP\": 0.49328420987394367,\n",
      "    \"Miou\": 0.4797450602748557,\n",
      "    \"Precision\": 0.3380879775551314,\n",
      "    \"Recall\": 0.6925031762816138,\n",
      "    \"F1\": 0.44427621620186347\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate_sceneseg.py baseline_preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "annual-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 make_baseline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-labor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
